{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Usage Cost and Sensitivity Analysis for GPT-4\n",
    "In this notebook, we'll calculate the total token cost of using a GPT-4 model for a given AI application and perform a **sensitivity analysis** to see how changes in different variables (e.g., daily requests, token usage) affect the total cost. Additionally, we will demonstrate how **prompt engineering** can reduce costs by optimizing token usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# GPT pricing parameters\n",
    "prompt_cost_per_1k_tokens = 0.03  # Cost per 1,000 tokens for input (prompt)\n",
    "completion_cost_per_1k_tokens = 0.06  # Cost per 1,000 tokens for output (completion)\n",
    "\n",
    "# Base parameters for token usage\n",
    "base_daily_requests = 1000  # Number of API requests per day\n",
    "base_prompt_tokens = 300  # Average tokens per prompt\n",
    "base_completion_tokens = 500  # Average tokens in GPT response\n",
    "days = 30  # Duration of usage in days\n",
    "\n",
    "# Function to calculate costs\n",
    "def calculate_token_cost(daily_requests, prompt_tokens, completion_tokens):\n",
    "    total_prompt_tokens = prompt_tokens * daily_requests * days\n",
    "    total_completion_tokens = completion_tokens * daily_requests * days\n",
    "    prompt_cost = (total_prompt_tokens / 1000) * prompt_cost_per_1k_tokens\n",
    "    completion_cost = (total_completion_tokens / 1000) * completion_cost_per_1k_tokens\n",
    "    total_cost = prompt_cost + completion_cost\n",
    "    return total_cost, prompt_cost, completion_cost\n",
    "\n",
    "# Step 1: Baseline cost calculation\n",
    "baseline_cost, baseline_prompt_cost, baseline_completion_cost = calculate_token_cost(\n",
    "    base_daily_requests, base_prompt_tokens, base_completion_tokens\n",
    ")\n",
    "\n",
    "print(\"Baseline Cost Analysis:\")\n",
    "print(f\"Total Token Cost: ${baseline_cost:,.2f}\")\n",
    "print(f\"Prompt Cost: ${baseline_prompt_cost:,.2f}\")\n",
    "print(f\"Completion Cost: ${baseline_completion_cost:,.2f}\\n\")\n",
    "\n",
    "# Step 2: Sensitivity analysis\n",
    "# Analyze the impact of daily requests and token usage\n",
    "daily_requests_range = np.arange(500, 2001, 500)  # Vary daily requests from 500 to 2000\n",
    "prompt_tokens_range = np.arange(100, 501, 100)  # Vary prompt token size from 100 to 500\n",
    "completion_tokens_range = np.arange(200, 801, 100)  # Vary completion token size from 200 to 800\n",
    "\n",
    "# Store results\n",
    "cost_matrix = []\n",
    "\n",
    "print(\"Sensitivity Analysis Results:\")\n",
    "print(\"Daily Requests | Prompt Tokens | Completion Tokens | Total Cost\")\n",
    "for daily_requests in daily_requests_range:\n",
    "    for prompt_tokens in prompt_tokens_range:\n",
    "        for completion_tokens in completion_tokens_range:\n",
    "            total_cost, _, _ = calculate_token_cost(daily_requests, prompt_tokens, completion_tokens)\n",
    "            cost_matrix.append((daily_requests, prompt_tokens, completion_tokens, total_cost))\n",
    "            print(f\"{daily_requests:<15}{prompt_tokens:<15}{completion_tokens:<19}${total_cost:,.2f}\")\n",
    "\n",
    "# Step 3: Impact of Prompt Engineering\n",
    "# Reducing prompt and completion tokens by 30%\n",
    "optimized_prompt_tokens = base_prompt_tokens * 0.7\n",
    "optimized_completion_tokens = base_completion_tokens * 0.7\n",
    "\n",
    "optimized_cost, optimized_prompt_cost, optimized_completion_cost = calculate_token_cost(\n",
    "    base_daily_requests, optimized_prompt_tokens, optimized_completion_tokens\n",
    ")\n",
    "\n",
    "print(\"\\nPrompt Engineering Impact:\")\n",
    "print(f\"Original Total Cost: ${baseline_cost:,.2f}\")\n",
    "print(f\"Optimized Total Cost (30% reduction in tokens): ${optimized_cost:,.2f}\")\n",
    "print(f\"Cost Savings: ${baseline_cost - optimized_cost:,.2f} ({((baseline_cost - optimized_cost) / baseline_cost) * 100:.2f}%)\")\n",
    "\n",
    "# Step 4: Visualization of Sensitivity Analysis\n",
    "# Convert sensitivity results into a heatmap\n",
    "# Create a DataFrame for heatmap visualization\n",
    "sensitivity_df = pd.DataFrame(cost_matrix, columns=[\"Daily Requests\", \"Prompt Tokens\", \"Completion Tokens\", \"Total Cost\"])\n",
    "\n",
    "# Pivot data for heatmap (e.g., vary prompt tokens and completion tokens for a fixed daily request)\n",
    "pivot_data = sensitivity_df[sensitivity_df[\"Daily Requests\"] == base_daily_requests].pivot(\n",
    "    \"Completion Tokens\", \"Prompt Tokens\", \"Total Cost\"\n",
    ")\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(pivot_data, annot=True, fmt=\".0f\", cmap=\"coolwarm\", cbar_kws={\"label\": \"Total Cost ($)\"})\n",
    "plt.title(f\"Sensitivity Analysis: Total Cost (Daily Requests = {base_daily_requests})\")\n",
    "plt.xlabel(\"Prompt Tokens\")\n",
    "plt.ylabel(\"Completion Tokens\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions for Running the Notebook:\n",
    "1. Copy the above code into a new Google Colab notebook or any Jupyter notebook environment.\n",
    "2. Run each cell sequentially to see the baseline cost analysis, sensitivity analysis, and the impact of prompt engineering.\n",
    "3. The sensitivity analysis will print the cost breakdown for various combinations of daily requests, prompt tokens, and completion tokens.\n",
    "4. A heatmap will visualize how the total cost changes with different configurations.\n",
    "5. You'll also see how reducing token usage (via prompt engineering) can save a significant portion of the cost."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
